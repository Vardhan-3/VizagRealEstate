# -*- coding: utf-8 -*-
"""RealBuddy Gemini API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ay9XWzqRoKczMwqhb994Xxg0KKhUr6Ec
"""

!pip install langchain-google-genai langchain langchain_community beautifulsoup4 requests pandas chromadb

"""#API Keys"""

import os, getpass
os.environ["GOOGLE_API_KEY"] = getpass.getpass("API Key:")

"""#Web Scraping"""

import requests, json, re, time, random
from bs4 import BeautifulSoup

HEADERS = {"User-Agent": "Mozilla/5.0"}

def scrape_magicbricks(city="Visakhapatnam", pages=5):
    data = []
    for p in range(1, pages+1):
        url = f"https://www.magicbricks.com/property-for-rent/residential-real-estate?&proptype=Multistorey-Apartment,Builder-Floor-Apartment,Penthouse,Studio-Apartment&cityName={city}&page={p}"
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, "lxml")
        cards = soup.select(".mb-srp__list")
        for c in cards:
            d = {
                "title": c.select_one(".mb-srp__card--title").text.strip() if c.select_one(".mb-srp__card--title") else None,
                "price": c.select_one(".mb-srp__card__price--amount").text.strip() if c.select_one(".mb-srp__card__price--amount") else None,
                "sqft": c.select_one(".mb-srp__card__summary--value").text.strip() if c.select_one(".mb-srp__card__summary--value") else None,
                "locality": c.select_one(".mb-srp__card--title+div").text.strip().split(",")[0] if c.select_one(".mb-srp__card--title+div") else None,
                "url": "https://www.magicbricks.com" + c.select_one("a")["href"] if c.select_one("a") else None
            }
            data.append(d)
        time.sleep(random.uniform(1,3))
    return data

vizag_listings = scrape_magicbricks(pages=5)

"""#Scraped Data to Json"""

with open("vizag_rentals.json", "w", encoding="utf-8") as f:
    json.dump(vizag_listings, f, ensure_ascii=False, indent=2)

"""#Building VectorDB with Scraped Data"""

from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.schema import Document

docs = [Document(
    page_content=f"{row['title']} in {row['locality']} priced at {row['price']} covering {row['sqft']}",
    metadata=row
) for row in vizag_listings]

vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001"),
    collection_name="vizag_rentals"
)

"""#LangChain Agent"""

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.tools.retriever import create_retriever_tool

retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
retriever_tool = create_retriever_tool(
    retriever,
    name="vizag_rental_search",
    description="Search for residential rental properties in Visakhapatnam with price, area and locality filters."
)

llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0)

tools = [retriever_tool]

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True
)

# 1. Re-build the vector store with correct Document structure
from langchain_core.documents import Document   # NEW import

docs = [
    Document(
        page_content=f"{row['title']} in {row['locality']} priced at {row['price']} covering {row['sqft']}",
        metadata={k: v for k, v in row.items()}   # keep metadata flat
    )
    for row in vizag_listings
]

# 2. Recreate vectorstore
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001"),
    collection_name="vizag_rentals",
    persist_directory="./chroma_db"   # optional persistence
)

# 3. Create the retriever tool
from langchain.tools.retriever import create_retriever_tool
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
vizag_tool = create_retriever_tool(
    retriever,
    name="vizag_rental_search",
    description="Search for residential rental properties in Visakhapatnam with price, area and locality filters."
)

# 4. Re-create the agent with modern syntax
from langchain.agents import create_react_agent, AgentExecutor
from langchain import hub

prompt = hub.pull("hwchase17/react")   # standard ReAct prompt
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)

agent = create_react_agent(llm, [vizag_tool], prompt)
agent_executor = AgentExecutor(agent=agent,
                               tools=[vizag_tool],
                               verbose=True,
                               handle_parsing_errors=True)

# 5. Query the agent (new call style)
agent_executor.invoke({"input": "What is average rent of Dwaraka Nagar?"})

# 5. Query the agent (new call style)
agent_executor.invoke({"input": "How many apartments are there in Visakhapatnam, with 2BHK?"})

# 5. Query the agent (new call style)
agent_executor.invoke({"input": "Can you say what is the cheapest place to live in Visakhapatnam"})

# 5. Query the agent (new call style)
agent_executor.invoke({"input": "What is the Rent of 3 BHK Flat for Rent in Vaisakhi SkyPark, Yendada, Visakhapatnam"})

"""#ADDITIONAL DATA SCRAPING"""

def scrape_housing(city="visakhapatnam", pages=3):
    """
    Quick scraper for https://housing.com (no login needed)
    """
    base = f"https://housing.com/in/buy/rent/search?f={city}&page="
    data = []
    for p in range(1, pages+1):
        url = base + str(p)
        r = requests.get(url, headers=HEADERS)
        soup = BeautifulSoup(r.text, "lxml")
        for card in soup.select("[data-testid='listing-card']"):
            price = card.select_one("[data-testid='price']")
            sqft  = card.select_one("[data-testid='area']")
            loc   = card.select_one("[data-testid='locality']")
            data.append({
                "title": card.select_one("h2").text.strip(),
                "price": price.text.strip() if price else None,
                "sqft":  sqft.text.strip()  if sqft  else None,
                "locality": loc.text.strip() if loc else None,
                "source": "housing.com"
            })
        time.sleep(random.uniform(1,3))`
    return data

# Merge into the same JSON file
more = scrape_housing()
vizag_listings.extend(more)

with open("vizag_rentals.json", "w", encoding="utf-8") as f:
    json.dump(vizag_listings, f, ensure_ascii=False, indent=2)

import re

def parse_number(txt):
    digits = re.sub(r'[^\d,]', '', str(txt))
    return int(digits.replace(',', '')) if digits else None

for row in vizag_listings:
    row["price_num"] = parse_number(row.get("price"))
    row["sqft_num"]  = parse_number(row.get("sqft"))

docs = [
    Document(
        page_content=f"{row['title']} in {row['locality']} priced at {row['price']} covering {row['sqft']}",
        metadata=row          # now includes price_num & sqft_num
    )
    for row in vizag_listings
]

vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001"),
    collection_name="vizag_rentals"
)

import pandas as pd
df = pd.DataFrame(vizag_listings).dropna(subset=["price_num", "sqft_num"])

def avg_rent_area(locality: str, max_rent: int):
    mask = (
        (df["locality"].str.contains(locality, case=False, na=False)) &
        (df["price_num"] <= max_rent)
    )
    subset = df[mask]
    if subset.empty:
        return "No matching listings found."
    return (
        f"Found {len(subset)} listings in {locality} ≤ ₹{max_rent:,}.\n"
        f"Average rent : ₹{subset['price_num'].mean():,.0f}\n"
        f"Average area : {subset['sqft_num'].mean():.0f} sqft"
    )

from langchain.tools import StructuredTool
avg_tool = StructuredTool.from_function(
    func=avg_rent_area,
    name="average_rent_area",
    description="Compute average rent & area given locality & max rent (₹)"
)

tools = [retriever_tool, avg_tool]

agent_executor = AgentExecutor(
    agent=create_react_agent(llm, tools, hub.pull("hwchase17/react")),
    tools=tools,
    verbose=True,
    handle_parsing_errors=True
)

agent_executor.invoke({
    "input": "I need a 2BHK in Dwaraka Nagar with rent below ₹15k. Show average rent and area."
})

"""#STREAM LIT"""

